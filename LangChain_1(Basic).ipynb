{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParitKansal/GenAI/blob/main/LangChain_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SUKUXK9h8XgL",
      "metadata": {
        "id": "SUKUXK9h8XgL"
      },
      "source": [
        "#**LangChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qo1DQXM18bgL",
      "metadata": {
        "id": "qo1DQXM18bgL"
      },
      "source": [
        "LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        "- GitHub: https://github.com/hwchase17/langchain\n",
        "- Docs: https://python.langchain.com/v0.2/docs/introduction/\n",
        "\n",
        "### Overview:\n",
        "- Installation\n",
        "- LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents and Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09CgA1RZkiC4",
      "metadata": {
        "id": "09CgA1RZkiC4"
      },
      "source": [
        "#**01: Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "X4tDdLTjkkk_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4tDdLTjkkk_",
        "outputId": "bead161c-e012-4238-d967-600c758250e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQHZiF38-Cps",
      "metadata": {
        "id": "sQHZiF38-Cps"
      },
      "source": [
        "#**02: Setup the Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9-mFf0Ql-KX2",
      "metadata": {
        "id": "9-mFf0Ql-KX2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f31c4cc6",
      "metadata": {
        "id": "f31c4cc6"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed0dc6a",
      "metadata": {
        "id": "9ed0dc6a"
      },
      "source": [
        "# **03: Large Language Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516GZwvpnVpV",
      "metadata": {
        "id": "516GZwvpnVpV"
      },
      "source": [
        "The basic building block of LangChain is a Large Language Model which takes text as input and generates more text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4FDyNMY3sRMc",
      "metadata": {
        "id": "4FDyNMY3sRMc"
      },
      "source": [
        "Suppose we want to generate a company name based on the company description, so we will first initialize an OpenAI wrapper. In this case, since we want the output to be more random, we will intialize our model with high temprature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLqFwlXaH8f4",
      "metadata": {
        "id": "eLqFwlXaH8f4"
      },
      "source": [
        "The temperature parameter adjusts the randomness of the output. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rMOonq5OH97v",
      "metadata": {
        "id": "rMOonq5OH97v"
      },
      "source": [
        "temperature value--> how creative we want our model to be\n",
        "\n",
        "0 ---> temperature it means model is  very safe it is not taking any bets.\n",
        "\n",
        "1 --> it will take risk it might generate wrong output but it is very creative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TB5tAUbT92Z7",
      "metadata": {
        "id": "TB5tAUbT92Z7"
      },
      "source": [
        "## **Open AI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "w-az-0Ex9CaD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-az-0Ex9CaD",
        "outputId": "7c5c12a1-ada8-4805-d02b-c851f05bf8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n5SJe7GfGiG",
        "outputId": "f60a96d0-3731-4544-b398-fed5ea93676b"
      },
      "id": "8n5SJe7GfGiG",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lJEy652utDdM",
      "metadata": {
        "id": "lJEy652utDdM"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_nF4R5EtN_k",
      "metadata": {
        "id": "n_nF4R5EtN_k"
      },
      "source": [
        "And now we will pass in text and get  predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "VIUqmBl3tUgj",
      "metadata": {
        "id": "VIUqmBl3tUgj"
      },
      "outputs": [],
      "source": [
        "text=\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "g7itCa0q9rn7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7itCa0q9rn7",
        "outputId": "cb55778b-570f-442f-d43d-73afafecd3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Imperial Dragon Palace\" \n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bj6wjnKZ-bgU",
      "metadata": {
        "id": "bj6wjnKZ-bgU"
      },
      "source": [
        "## **Hugging Face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "hDMLw7Yr-nQK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMLw7Yr-nQK",
        "outputId": "ff42f1c3-6c6f-406a-bb93-439e9d93ab68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.26.2)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.18)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.2.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.20.3)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.1.143)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "B4w0ultA-icd",
      "metadata": {
        "id": "B4w0ultA-icd"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "W-pl8cXk-ie7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-pl8cXk-ie7",
        "outputId": "844c7617-32c1-465f-ebd6-d5e6ca1dc526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1994 FIFA World Cup was won by Brazil. Brazil won the tournament by defeating Italy in the final match, which took place on July 17, 1994. This was Brazil's fourth World Cup title, and they won it under the leadership of their legendary coach, Carlos Alberto Parreira. The final match was held at the Rose Bowl in Pasadena, California, United States. Brazil won the match 0-0 in regular time, and won the title in the penalty shootout. The team's star players included Romário, Ronaldo (Ronaldinho's elder brother), Dunga, and Cafu, among others.\n"
          ]
        }
      ],
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    max_length=5,\n",
        "    temperature=0.5,\n",
        ")\n",
        "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
        "print(llm.invoke(question))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0782a2dd",
      "metadata": {
        "id": "0782a2dd"
      },
      "source": [
        "# **04: Prompt Templates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jszTHb6J_dNV",
      "metadata": {
        "id": "jszTHb6J_dNV"
      },
      "source": [
        "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unU1DcEv7TWh",
      "metadata": {
        "id": "unU1DcEv7TWh"
      },
      "source": [
        "In many Large Language Model applications we do not pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IWqka6F_93QB",
      "metadata": {
        "id": "IWqka6F_93QB"
      },
      "source": [
        "## **Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7a306b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a306b9d",
        "outputId": "6215b589-c64a-43af-aea1-c3a12b254852",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for indian food. Suggest 2 fancy names for this.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=['cuisine', 'count'],  # List of input variable names\n",
        "    input_types={'cuisine': str, 'count': int},  # Types of the input variables\n",
        "    template=\"I want to open a restaurant for {cuisine} food. Suggest {count} fancy names for this.\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(cuisine=\"indian\", count=2)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qlKeWd7B95-R",
      "metadata": {
        "id": "qlKeWd7B95-R"
      },
      "source": [
        "## **Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "qqJZBS9u8534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqJZBS9u8534",
        "outputId": "5eac1f52-2ee2-4ddf-b96c-c31d202fa5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for Chinese food. Suggest 5 fancy names for this.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=['cuisine', 'count'],  # List of input variable names\n",
        "    input_types={'cuisine': str, 'count': int},  # Types of the input variables\n",
        "    template=\"I want to open a restaurant for {cuisine} food. Suggest {count} fancy names for this.\"\n",
        ")\n",
        "\n",
        "def format_with_defaults(cuisine=\"indian\", count=2):\n",
        "    return prompt_template_name.format(cuisine=cuisine, count=count)\n",
        "\n",
        "p = format_with_defaults(\"Chinese\", \"5\")\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O3YEt1YZKJHr",
      "metadata": {
        "id": "O3YEt1YZKJHr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "af406b92",
      "metadata": {
        "id": "af406b92"
      },
      "source": [
        "# **05: Chains**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vGaSSUAIBHdU",
      "metadata": {
        "id": "vGaSSUAIBHdU"
      },
      "source": [
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lcjlXP7z_-k6",
      "metadata": {
        "id": "lcjlXP7z_-k6"
      },
      "source": [
        "Now as we have the  **model**:\n",
        "\n",
        "```\n",
        "llm = OpenAI(temperature=0.9)\n",
        "```\n",
        "\n",
        "\n",
        "and the **Prompt Template**:\n",
        "```\n",
        "prompt =  PromptTemplate(\n",
        "    input_variables=['cuisine', 'count'],  # List of input variable names\n",
        "    input_types={'cuisine': str, 'count': int},  # Types of the input variables\n",
        "    template=\"I want to open a restaurant for {cuisine} food. Suggest {count} fancy names for this.\"\n",
        ")\n",
        "prompt.format(cuisine=\"indian\", count=2)\n",
        "```\n",
        "\n",
        "Now using Chains we will link together model and the PromptTemplate and other Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mIJx5zL2BbHJ",
      "metadata": {
        "id": "mIJx5zL2BbHJ"
      },
      "source": [
        "The simplest and most common type of Chain is LLMChain, which passes the input first to Prompt Template and then to Large Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5icZHtlDFrpI",
      "metadata": {
        "id": "5icZHtlDFrpI"
      },
      "source": [
        "LLMChain is responsible to execute the PromptTemplate, For every PromptTemplate we will specifically have an LLMChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MAUSugfLCZH-",
      "metadata": {
        "id": "MAUSugfLCZH-"
      },
      "source": [
        "### **Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "22NEqcvGGvHJ",
      "metadata": {
        "id": "22NEqcvGGvHJ"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "bK-KESsGGOhY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bK-KESsGGOhY",
        "outputId": "760d3e88-fc10-49bf-c64c-0b9476d9e6c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to open a restaurant for indian food. Suggest 2 fancy names for this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt =  PromptTemplate(\n",
        "    input_variables=['cuisine', 'count'],  # List of input variable names\n",
        "    input_types={'cuisine': str, 'count': int},  # Types of the input variables\n",
        "    template=\"I want to open a restaurant for {cuisine} food. Suggest {count} fancy names for this.\"\n",
        ")\n",
        "prompt.format(cuisine=\"indian\", count=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8KjGw4iXGUGJ",
      "metadata": {
        "id": "8KjGw4iXGUGJ"
      },
      "source": [
        "Whatever input text i am giving that will get assigned to this particular variable that is **product**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "1gatUl_ICZOP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1gatUl_ICZOP",
        "outputId": "5e7a536e-c132-432e-e56c-bed658974743"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. \"TajMahal Bites\" \\n2. \"Spice Palace Dining\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response= chain.run(cuisine = \"indian\", count = 2)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O93s1iRICXNv",
      "metadata": {
        "id": "O93s1iRICXNv"
      },
      "source": [
        "### **Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "e5ccee75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ccee75",
        "outputId": "a42091b1-d530-4485-fc3b-27efbcb1d77a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest 2 fancy names for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "1. \"El Sabor Exótico\" (The Exotic Flavor)\n",
            "2. \"La Fiesta de Sabores\" (The Flavor Party)\n"
          ]
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "response=chain.run(cuisine = \"Mexican\", count = 2)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a-6_6H-BJl9L",
      "metadata": {
        "id": "a-6_6H-BJl9L"
      },
      "source": [
        "## **To combine the Chain and  to set a sequence for that we use SimpleSequentialChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EMd9OQVNH7lK",
      "metadata": {
        "id": "EMd9OQVNH7lK"
      },
      "source": [
        "**Can we combine Multiple PromptTemplates, We will try to combine Multiple PromptTemplates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nv_tlKtLJLIZ",
      "metadata": {
        "id": "nv_tlKtLJLIZ"
      },
      "source": [
        "**The output from the first PromptTemplate is passed to the next PromptTemplate as input**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a98d9f",
      "metadata": {
        "id": "87a98d9f"
      },
      "source": [
        "###**Simple Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "21098937",
      "metadata": {
        "id": "21098937"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(temperature=0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, verbose = True)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items,verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "d9fd9a79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9fd9a79",
        "outputId": "8d9b31a5-e0de-4b3b-dc18-9f4e823afec7",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "\"Spice Symphony\"\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest some menu items for \n",
            "\n",
            "\"Spice Symphony\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "1. Tandoori Chicken Tikka\n",
            "2. Lamb Vindaloo\n",
            "3. Vegetable Samosas\n",
            "4. Butter Chicken\n",
            "5. Palak Paneer\n",
            "6. Masala Dosa\n",
            "7. Garlic Naan\n",
            "8. Chana Masala\n",
            "9. Mango Lassi\n",
            "10. Gulab Jamun (dessert)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain], verbose = True)\n",
        "\n",
        "content = chain.run(\"indian\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "njqmmiouJ6Uc",
      "metadata": {
        "id": "njqmmiouJ6Uc"
      },
      "source": [
        "**There is a issue with SimpleSequentialChain it only shows last input information**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hKVVpZo8KC38",
      "metadata": {
        "id": "hKVVpZo8KC38"
      },
      "source": [
        "## **To show the entire information i will use SequentialChain(Good)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386d05c",
      "metadata": {
        "id": "0386d05c"
      },
      "source": [
        "### **Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "49dc0fae",
      "metadata": {
        "id": "49dc0fae"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\",verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "9dea8402",
      "metadata": {
        "id": "9dea8402"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name','count'],\n",
        "    template=\"Suggest {count} menu items for {restaurant_name}.\"\n",
        ")\n",
        "food_items_chain0 =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items0\", verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name','count','cuisine'],\n",
        "    template=\"Suggest {count} menu items in {cuisine} cusine for restaurant named: {restaurant_name}.\"\n",
        ")\n",
        "food_items_chain1 = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items1\", verbose = True)"
      ],
      "metadata": {
        "id": "_F6pwBIt4S7x"
      },
      "id": "_F6pwBIt4S7x",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "1ec1be10",
      "metadata": {
        "id": "1ec1be10"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain0, food_items_chain1],\n",
        "    input_variables = ['cuisine', 'count'],\n",
        "    output_variables = ['restaurant_name', \"menu_items0\", \"menu_items1\"],\n",
        "    verbose = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "4653c540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4653c540",
        "outputId": "5fb3b1bc-f8dd-4653-cd3d-80c247ce2c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest 5 menu items for \n",
            "\n",
            "\"Spice Palace\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest 5 menu items in indian cusine for restaurant named: \n",
            "\n",
            "\"Spice Palace\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'count': '5', 'restaurant_name': '\\n\\n\"Spice Palace\"', 'menu_items0': '\\n\\n1. Spicy Chicken Curry: Tender pieces of chicken cooked in a rich, flavorful curry sauce with a kick of spice.\\n\\n2. Vegetable Samosas: Crispy pastry pockets filled with a medley of seasoned vegetables and served with a spicy dipping sauce.\\n\\n3. Lamb Vindaloo: Slow-cooked lamb in a fiery vindaloo sauce, perfect for those who love a little heat in their meal.\\n\\n4. Aloo Gobi: A classic vegetarian dish made with cauliflower and potatoes, seasoned with aromatic spices and chili peppers.\\n\\n5. Tandoori Shrimp: Succulent shrimp marinated in a spicy blend of herbs and spices, then grilled in a traditional tandoor oven.', 'menu_items1': '\\n\\n1. Tandoori Chicken: Marinated chicken cooked in a traditional clay oven, served with a side of naan bread and mint chutney.\\n\\n2. Butter Chicken: Tender chicken simmered in a creamy tomato and butter sauce, served with basmati rice and garlic naan.\\n\\n3. Vegetable Biryani: Fragrant basmati rice cooked with assorted vegetables, spices, and herbs, served with raita and papadum.\\n\\n4. Lamb Rogan Josh: Slow-cooked lamb in a flavorful onion and tomato-based sauce, served with naan bread and cucumber yogurt.\\n\\n5. Palak Paneer: Fresh spinach and cottage cheese cubes cooked in a spiced tomato and cream sauce, served with basmati rice and garlic naan.'}\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"cuisine\":\"indian\", \"count\":\"5\"}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-community langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTwa73PqFA-G",
        "outputId": "d70523fe-0bad-4959-a248-6e39187ba857"
      },
      "id": "LTwa73PqFA-G",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.4)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Downloading langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.2.9 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "def generate_restaurant_details(cuisine: str = \"Indian\", count: int = 5):\n",
        "    llm = OpenAI(temperature=0.7)\n",
        "\n",
        "    # Define the prompt template for restaurant name\n",
        "    prompt_template_name = PromptTemplate(\n",
        "        input_variables=['cuisine'],\n",
        "        template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        "    )\n",
        "    name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
        "\n",
        "    # Define the prompt template for menu items without specifying cuisine\n",
        "    prompt_template_items0 = PromptTemplate(\n",
        "        input_variables=['restaurant_name', 'count'],\n",
        "        template=\"Suggest {count} menu items for {restaurant_name}.\"\n",
        "    )\n",
        "    food_items_chain0 = LLMChain(llm=llm, prompt=prompt_template_items0, output_key=\"menu_items0\")\n",
        "\n",
        "    # Define the prompt template for menu items with cuisine specified\n",
        "    prompt_template_items1 = PromptTemplate(\n",
        "        input_variables=['restaurant_name', 'count', 'cuisine'],\n",
        "        template=\"Suggest {count} menu items in {cuisine} cuisine for restaurant named: {restaurant_name}.\"\n",
        "    )\n",
        "    food_items_chain1 = LLMChain(llm=llm, prompt=prompt_template_items1, output_key=\"menu_items1\")\n",
        "\n",
        "    # Create the sequential chain\n",
        "    chain = SequentialChain(\n",
        "        chains=[name_chain, food_items_chain0, food_items_chain1],\n",
        "        input_variables=['cuisine', 'count'],\n",
        "        output_variables=['restaurant_name', 'menu_items0', 'menu_items1'],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Execute the chain\n",
        "    return chain.invoke({\"cuisine\": cuisine, \"count\": count})\n",
        "\n",
        "# Example usage\n",
        "result = generate_restaurant_details(\"indian\", 5)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyxcgs1b607b",
        "outputId": "1a44a031-d246-4624-f790-da6f560e8648"
      },
      "id": "Pyxcgs1b607b",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'count': 5, 'restaurant_name': '\\n\\n\"Spice Palace\"', 'menu_items0': '\\n\\n1. \"Spicy Chicken Curry\": Tender chunks of chicken cooked in a rich and flavorful curry sauce, served with fragrant basmati rice.\\n\\n2. \"Paneer Tikka Masala\": Marinated and grilled paneer (Indian cottage cheese) cooked in a creamy tomato sauce, served with naan bread.\\n\\n3. \"Lamb Vindaloo\": A classic Goan-style dish with tender lamb pieces cooked in a spicy and tangy vindaloo sauce, served with steamed rice.\\n\\n4. \"Vegetable Biryani\": A colorful and aromatic rice dish made with mixed vegetables, herbs, and spices, served with raita (yogurt sauce).\\n\\n5. \"Tandoori Mixed Grill\": A platter of assorted tandoori meats including chicken tikka, lamb seekh kebab, and tandoori shrimp, served with mint chutney and naan bread.', 'menu_items1': '\\n\\n1. Butter Chicken: Tender chicken pieces simmered in a rich and creamy tomato gravy, flavored with aromatic spices.\\n2. Vegetable Biryani: Fragrant basmati rice cooked with assorted vegetables and spices, served with raita.\\n3. Tandoori Mixed Grill: Assortment of tandoori chicken, lamb tikka, and seekh kebab served with naan bread and mint chutney.\\n4. Palak Paneer: Homemade cottage cheese cubes cooked in a creamy spinach gravy, served with naan bread.\\n5. Masala Dosa: Thin crispy crepe made from fermented rice and lentil batter, filled with spiced potato filling and served with coconut chutney and sambar.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069a75e",
      "metadata": {
        "id": "4069a75e"
      },
      "source": [
        "# **06. Agents and Tools**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z-4QjS31LD_s",
      "metadata": {
        "id": "Z-4QjS31LD_s"
      },
      "source": [
        "\n",
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use.\n",
        "\n",
        "Agent is a very powerful concept in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GgNLQ6kSL4na",
      "metadata": {
        "id": "GgNLQ6kSL4na"
      },
      "source": [
        "For example I have to travel from Dubai to Canada, I type this in ChatGPT\n",
        "\n",
        "\n",
        "\n",
        "---> Give me  two flight options from Dubai to Canada on September 1, 2024 | ChatGPT will not be able to answer because has knowledge till\n",
        "September 2021\n",
        "\n",
        "\n",
        "\n",
        "ChatGPT plus has Expedia Plugin, if we enable this plugin it will go to Expedia Plugin and will try to pull information about Flights & it will show the information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tkzApnDnJy8p",
      "metadata": {
        "id": "tkzApnDnJy8p"
      },
      "source": [
        "SerpApi is a real-time API to access Google search results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cd3a12",
      "metadata": {
        "id": "09cd3a12"
      },
      "source": [
        "#### Wikipedia and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "TpJ3gA4YZKMx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpJ3gA4YZKMx",
        "outputId": "179efe9e-1c52-4316-cdd7-a7b8fd18ae66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=11f454520a7b99e3d932bf44d7811bfabf460537c0aa1c76f57f5d22b4d31094\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "kb7ZpkpcVIYO",
      "metadata": {
        "id": "kb7ZpkpcVIYO"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UvJNqWvTVKcd",
      "metadata": {
        "id": "UvJNqWvTVKcd"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d06ce6",
      "metadata": {
        "id": "14d06ce6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    # Handle the issue by setting handle_parsing_errors to True.\n",
        "    # This should allow the agent to handle the parsing errors and continue execution.\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"What was the GDP of US in 2021?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6be7ee7",
      "metadata": {
        "id": "b6be7ee7"
      },
      "source": [
        "# **07: Memory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-WkJqQzRZaXL",
      "metadata": {
        "id": "-WkJqQzRZaXL"
      },
      "source": [
        "Chatbot application like ChatGPT, you will notice that it remember past information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "Iqunzha0Ztuz",
      "metadata": {
        "id": "Iqunzha0Ztuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc514218-2feb-4f5b-cf21-0541c8791a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"La Cantina del Sol\"\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "229a6888",
      "metadata": {
        "id": "229a6888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09cea37-a114-4be9-f952-21586a474977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871492be",
      "metadata": {
        "id": "871492be"
      },
      "source": [
        "### **ConversationBufferMemory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coQKpk8jZ8zz",
      "metadata": {
        "id": "coQKpk8jZ8zz"
      },
      "source": [
        "We can attach memory to remember all previous conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "53eea298",
      "metadata": {
        "id": "53eea298"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.invoke(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylGRt6tDPHSo",
        "outputId": "fba8d7c3-7777-4472-e1ae-1427cb215c35"
      },
      "id": "ylGRt6tDPHSo",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'Mexican', 'history': '', 'text': '\\n\\n\"El Sabor de México\" (The Flavor of Mexico)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0de5d50b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0de5d50b",
        "outputId": "c33a1cb1-092d-44aa-a355-acdc032d110e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'Arabic', 'history': 'Human: Arabic\\nAI: \\n\\n\"Saffron Oasis\"\\nHuman: Mexican\\nAI: \\n\"El Sabor Divino\" (The Divine Flavor)\\nHuman: Arabic\\nAI: \\n\\nAl-Jazeerah Palace ', 'text': '\\n\"The Arabian Bistro\"'}\n"
          ]
        }
      ],
      "source": [
        "name = chain.invoke(\"Arabic\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "5cc88888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc88888",
        "outputId": "a02b1f58-9559-461d-a828-149a00c24f87",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\"El Sabroso Cantina\"', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Saffron Oasis\"', additional_kwargs={}, response_metadata={}), HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\"El Sabor Divino\" (The Divine Flavor)', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\nAl-Jazeerah Palace ', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\"The Arabian Bistro\"', additional_kwargs={}, response_metadata={})]) k=3\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a88b5b",
      "metadata": {
        "id": "a0a88b5b"
      },
      "source": [
        "### **ConversationChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FyFmOOemaVxb",
      "metadata": {
        "id": "FyFmOOemaVxb"
      },
      "source": [
        "Conversation buffer memory goes growing endlessly\n",
        "\n",
        "Just remember last 5 Conversation Chain\n",
        "\n",
        "Just remember last 10-20 Conversation Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "687ddd2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687ddd2f",
        "outputId": "90f6be7e-39dd-4d68-f2c0-fb22d83bccbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-ffeb4aaf188e>:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  convo = ConversationChain(llm=OpenAI(temperature=0.7))\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "47ad5062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "47ad5062",
        "outputId": "1a30114c-9eb1-49ac-c88c-6948d1be42b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The first Cricket World Cup was held in 1975 and was won by the West Indies. The final match was played between the West Indies and Australia at Lord's Cricket Ground in London, England. The West Indies won by 17 runs. The captain of the winning team was Clive Lloyd and the player of the tournament was Australia's Gary Gilmour.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "03c80b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "03c80b54",
        "outputId": "29402704-bedd-4235-8e0c-5ec2964fb9fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "07342f88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "07342f88",
        "outputId": "ce1935af-78ef-4b77-c99c-e668b2f8fbc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler who played for the West Indies from 1966 to 1985. He led the West Indies to two consecutive World Cup victories in 1975 and 1979. He was also known as the \"Supercat\" for his athletic fielding abilities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4e459d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e459d07",
        "outputId": "16d69ee4-a561-47a8-975c-2e3d91f58611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first Cricket World Cup was held in 1975 and was won by the West Indies. The final match was played between the West Indies and Australia at Lord's Cricket Ground in London, England. The West Indies won by 17 runs. The captain of the winning team was Clive Lloyd and the player of the tournament was Australia's Gary Gilmour.\n",
            "Human: How much is 5+5?\n",
            "AI:   5+5 is equal to 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler who played for the West Indies from 1966 to 1985. He led the West Indies to two consecutive World Cup victories in 1975 and 1979. He was also known as the \"Supercat\" for his athletic fielding abilities.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaa3abd",
      "metadata": {
        "id": "feaa3abd"
      },
      "source": [
        "### **ConversationBufferWindowMemory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "460eb33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "460eb33c",
        "outputId": "e2efe4ea-a8be-49fc-b7ce-4689d5b1af57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-199197ae7820>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(k=3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies in 1975. It was held in England and the West Indies beat Australia by 17 runs in the final match. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards, who scored 138 runs. It was a historic moment for the West Indies team and for cricket as a whole. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=3)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyMr8m5MQemG",
        "outputId": "4db54895-55d2-48d0-ddec-31a6cbb96c7e"
      },
      "id": "kyMr8m5MQemG",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies in 1975. It was held in England and the West Indies beat Australia by 17 runs in the final match. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards, who scored 138 runs. It was a historic moment for the West Indies team and for cricket as a whole. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d395beaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d395beaf",
        "outputId": "471fea2d-2cef-4199-ee98-80a240e16a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The result of 5+5 is 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kz13IYgQf4y",
        "outputId": "b5da51d9-6871-48ff-da2b-ea78e4a314d9"
      },
      "id": "1kz13IYgQf4y",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies in 1975. It was held in England and the West Indies beat Australia by 17 runs in the final match. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards, who scored 138 runs. It was a historic moment for the West Indies team and for cricket as a whole. \n",
            "Human: How much is 5+5?\n",
            "AI:  The result of 5+5 is 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "93b24745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "93b24745",
        "outputId": "1491dd3c-bd0f-48a7-f661-0639c01a5c25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "K63Ie5FTvjzo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K63Ie5FTvjzo",
        "outputId": "cc3fcd98-d856-4ef5-b29e-ed1cef0b229f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies in 1975. It was held in England and the West Indies beat Australia by 17 runs in the final match. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards, who scored 138 runs. It was a historic moment for the West Indies team and for cricket as a whole. \n",
            "Human: How much is 5+5?\n",
            "AI:  The result of 5+5 is 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was Clive Lloyd?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "vwUcsm0jQl7s",
        "outputId": "98aa4060-774b-4d67-ec2b-1a847829abbf"
      },
      "id": "vwUcsm0jQl7s",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Clive Lloyd is a former West Indian cricketer who played for the West Indies national team from 1966 to 1985. He is considered one of the greatest cricketers of all time and was known for his strong leadership skills as captain of the West Indies team. He led the team to multiple victories, including the first and second cricket world cups in 1975 and 1979. After his retirement, he went on to serve as a coach and administrator for cricket in the West Indies.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxUD9de7QqkC",
        "outputId": "39571ae8-cf44-4bbe-99f7-a5af42c267c8"
      },
      "id": "gxUD9de7QqkC",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: How much is 5+5?\n",
            "AI:  The result of 5+5 is 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd.\n",
            "Human: Who was Clive Lloyd?\n",
            "AI:  Clive Lloyd is a former West Indian cricketer who played for the West Indies national team from 1966 to 1985. He is considered one of the greatest cricketers of all time and was known for his strong leadership skills as captain of the West Indies team. He led the team to multiple victories, including the first and second cricket world cups in 1975 and 1979. After his retirement, he went on to serve as a coach and administrator for cricket in the West Indies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkFhYXKUmnDO",
      "metadata": {
        "id": "mkFhYXKUmnDO"
      },
      "source": [
        "#**08: Document Loaders**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "-9WXxhHCZtTn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9WXxhHCZtTn",
        "outputId": "68916de1-e879-42ba-f45a-16ed24e2019a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "wqlRJc7DmtwA",
      "metadata": {
        "id": "wqlRJc7DmtwA"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\n",
        "    \"/content/Parit_Kansal.pdf\",\n",
        ")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "XGTtdS26mt0_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGTtdS26mt0_",
        "outputId": "5e15390d-47b9-42d9-c7e4-8155921433fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last Upda ted on 18th No vember 2024 \n",
            "Parit Kansal\n",
            "paritk ansal121@gmail.c om | (+91 ) 6 39-895 -0353 \n",
            "EDUCATION\n",
            "HARCOURT BUTLER TECHNICAL\n",
            "UNIVERSITY\n",
            "B. Tech in Computer Science & \n",
            "Engineering \n",
            "2025 | K anpur, India \n",
            "CGPA:8.132\n",
            "DEWAN PUBLIC SCHOOL\n",
            "Senior School \n",
            "Ma y 2020 | Hapur, India \n",
            "Percentage: 94%\n",
            "DEWAN PUBLIC SCHOOL\n",
            "High School \n",
            "Ma y 2018 | Hapur, India \n",
            "Percentage: 98%\n",
            "LINKS\n",
            "Website://paritkansal121.odoo.com\n",
            "Github://ParitKansal\n",
            "LinkedIn://paritkansal\n",
            "LeetCode://ParitKansal\n",
            "COURSEWORK\n",
            "UNDERGRADUATE\n",
            "Compiler Design\n",
            "Computer Networks\n",
            "Computer Organization & Architecture\n",
            "Data Science\n",
            "Database Management Systems\n",
            "Numerical & Statistical Techniques\n",
            "Operating Systems\n",
            "Web Technology\n",
            "SKILLS\n",
            "LANGUAGES\n",
            "• Python • C++ • C\n",
            "INTERESTS\n",
            "• Data Science • ML • Deep Learning\n",
            "• Computer Vision • NLP\n",
            "TOOLS AND TECHNOLOGIES\n",
            "• MS Azure, • MySQL • Power BI • LLM\n",
            "• Web Scraping • MS Excel-VBA\n",
            "FRAMEWORKS\n",
            "• TensorFlow• PyTorch• Sparky\n",
            "SOFT SKILLS\n",
            "• Teamwork• Problem Solving\n",
            "• Communication\n",
            "EXPERIENCE\n",
            "EXTION INFOTECH| AI Intern \n",
            "J ul y 2024 - A ug 2024 | Remo te \n",
            "• Developed an API for web scraping using LLM for data filtering, producing\n",
            "JSON output, which improved data processing efficiency. Created\n",
            "datasets and fine-tuned a Hugging Face models.\n",
            "• Built a hybrid recommendation system in Python using Suprise, comparing\n",
            "various algorithms, which improved recommendation accuracy and user\n",
            "engagement.\n",
            "• Developed a web app to summarize videos and extractkey points,\n",
            "enhancing content accessibility and user comprehension.\n",
            "VODAFONE IDEA FOUNDATION| Data Analytics Intern \n",
            "J une 2024 - J ul y 2024 | Remo te \n",
            "• Getting insights for sales by building a predicative model (L1 Regression &\n",
            "Bayesian Regression) with predictors like price, distribution, competitions\n",
            "and promotion.\n",
            "• Build a simulator/dashboardin Power BI to simulate sales change with\n",
            "change in sales drivers such as price, promotion, distribution, media\n",
            "spending and competition changes.\n",
            "PROJECTS\n",
            "VIDEO QUEST| Gen AI \n",
            "J ul y 2024 \n",
            "A web app that summarizes videos, extractskey points, and offers Q&A for quick\n",
            "insights.\n",
            "RECOMMENDATION SYSTEM| ML \n",
            "J une 2024 \n",
            "Built using algorithms like SVD, ContentKNN, and RBM; compared based on\n",
            "metrics like RMSE and Hit Rate.\n",
            "RECRUIT EASE CHATBOT| NLP \n",
            "Feb 2024 \n",
            "A chatbot for recruiters to quickly access resume details like skills and\n",
            "experience.\n",
            "IMAGE CLASSIFICATION AND OBJECT LOCALIZATION| Computer \n",
            "Vision \n",
            "Dec 2023 \n",
            "Python project to classify single digits subjects in images and localize them using\n",
            "bounding boxes.\n",
            "QUORA QUESTION PAIRS| NLP \n",
            "Oct 2023 \n",
            "NLP project build using using more than 0.4 million rows of data and predicting\n",
            "if question pairs are similar,achieving 82.3% accuracy.\n",
            "CERTIFICATION\n",
            "June 2024 Coursera TensorFlow: Advanced Techniques\n",
            "June 2024 LinkedIn Advance YourSkills as a Machine Learning\n",
            "specialist\n",
            "Apr 2024 freeCodeCamp Machine Learning with Python\n",
            "ACHIEVEMENTS\n",
            "• Solved about 1200 DSA questions on different platforms including Leetcode\n",
            "and GeeksforGeeks.\n",
            "• Secured 4th rank in Hapur district in Class XII.\n",
            "• Secured 3rd rank in Hapur district in Class X.\n"
          ]
        }
      ],
      "source": [
        "print(pages[0].page_content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "09CgA1RZkiC4",
        "sQHZiF38-Cps",
        "9ed0dc6a",
        "TB5tAUbT92Z7",
        "bj6wjnKZ-bgU",
        "0782a2dd",
        "IWqka6F_93QB",
        "qlKeWd7B95-R",
        "af406b92",
        "MAUSugfLCZH-",
        "O93s1iRICXNv",
        "a-6_6H-BJl9L",
        "87a98d9f",
        "hKVVpZo8KC38",
        "4069a75e"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
